{"cells":[{"cell_type":"markdown","id":"745719ae","metadata":{"id":"745719ae"},"source":["# Part 1"]},{"cell_type":"markdown","id":"0cf5ce68","metadata":{"id":"0cf5ce68"},"source":["In this part of the project, you will design and create a knowledge base, and then\n","compare different methods for performing inference on that knowledge base. <br>\n","\n","**Description of the problem** <br>\n","\n","- *Anjali*, *Brian*, and *Chen* graduated from QUB on different days this summer. <br>\n","\n","- One of them studied *French*, one studied *Geography*, one read *History*. <br>\n","\n","- One scored a *very good 65%*, one acheived an *excellent 70%*, and the other an *outstanding 75%*. <br>\n","\n","- They graduated on the *2nd*, *3rd*, and *4th* July. <br>\n","\n","We have acquired some knowledge about who studied what, what their marks were,\n","and when they graduated. However, our knowledge is incomplete. <br>\n","\n","\n","**Here is what we know:** <br>\n","\n","1. Chen’s mark was lower than the mark of the person who studied French. <br>\n","\n","2. The three people are Brian, the person who studied History, the person who graduated on the 2nd. <br>\n","\n","3. Chen scored 70%, unless she studied history in which case her mark was 65%. <br>\n","\n","4. The mark of the person who graduated on the 3rd was 5% higher than Chen’s. <br>\n","\n","5. Anjali did not graduate on the 2nd. <br>\n","\n","**The goal of this assignment is to determine who acheived which mark, what each person studied, and when they graduated** <br>"]},{"cell_type":"markdown","id":"d4fb5c47","metadata":{"id":"d4fb5c47"},"source":["## Task (a)\n","\n","Formulate a knowledge base (KB) for this problem using propositional logic. Explicitly state how each clue entails the sentences in the knowledge\n","base that are derived from it."]},{"cell_type":"markdown","id":"1f2ccac9","metadata":{"id":"1f2ccac9"},"source":["**Table of Available Knowledge** <br>\n","\n","| Student | Subject | Mark | Graduated Date |\n","| ----------- | ----------- | ----------- | ----------- |\n","| Anjali | French | Very Good 65% | 2nd July |\n","| Brian | Geography | Excellent 70% | 3rd July |\n","| Chen | History | Outstanding 75% | 4th July |\n","\n"," **Atomic Propositions** <br>\n","\n","$A_F$: Anjali studied French. <br>\n","$B_F$: Brian studied French. <br>\n","$C_F$: Chen studied French. <br>\n","\n","$A_G$: Anjali studied Geography. <br>\n","$B_G$: Brian studied Geography. <br>\n","$C_G$: Chen studied Geography. <br>\n","\n","$A_H$: Anjali studied History. <br>\n","$B_H$: Brian studied History. <br>\n","$C_H$: Chen studied History. <br>\n","\n","$A_{65}$: Anjali scored Very Good 65%. <br>\n","$B_{65}$: Brian scored Very Good 65%. <br>\n","$C_{65}$: Chen scored Very Good 65% <br>\n","\n","$A_{70}$: Anjali scored Excellent 70%. <br>\n","$B_{70}$: Brian scored Excellent 70%. <br>\n","$C_{70}$: Chen scored Excellent 70%. <br>\n","\n","$A_{75}$: Anjali scored Oustanding 75%. <br>\n","$B_{75}$: Brian scored Oustanding 75%. <br>\n","$C_{75}$: Chen scored Oustanding 75%. <br>\n","\n","$A_{2}$: Anjali graduated on 2nd July. <br>\n","$B_{2}$: Brian graduated on 2nd July. <br>\n","$C_{2}$: Chen graduated on 2nd July. <br>\n","\n","$A_{3}$: Anjali graduated on 3rd July. <br>\n","$B_{3}$: Brian graduated on 3rd July. <br>\n","$C_{3}$: Chen graduated on 3rd July. <br>\n","\n","$A_{4}$: Anjali graduated on 4th July. <br>\n","$B_{4}$: Brian graduated on 4th July. <br>\n","$C_{4}$: Chen graduated on 4th July. <br>"]},{"cell_type":"markdown","id":"9ecac8e7","metadata":{"id":"9ecac8e7"},"source":["**Clues**\n","\n","**1. Chen’s mark was lower than the mark of the person who studied French.** <br>\n","\n","Note[1]: Based on Clue(1), Chen didn't study French since there is the other student who studied French.\n","\n","- $R_{1}$: $\\lnot C_F$\n","\n","Note[2]: If Chen didn't study French, then one of the other two students studied French.\n","\n","- $R_{2}$: $\\lnot C_F \\implies (A_F \\lor B_F)$\n","\n","Note[3]: Based on Clue(1), Chen didn't score the highest mark in order for Chen's mark to be lower than the French student's mark.\n","\n","- $R_{3}$: $\\lnot C_{75}$\n","\n","Note[4]: If Chen scored 70%, then Anjali studied French & scored 75% (or) Brian studied French & scored 75%.\n","\n","- $R_{4}$: $C_{70} \\implies (A_F \\land A_{75}) \\lor (B_F \\land B_{75})$\n","\n","Note[5]: If Chen scored 65%, then Anjali studied French & scored 75% (or) Brian studied French & scored 75% (or) Anjali studied French & scored 70% (or) Brian studied French & scored 70%.\n","\n","- $R_{5}$: $C_{65} \\implies (A_F \\land A_{75}) \\lor (B_F \\land B_{75}) \\lor (A_F \\land A_{70}) \\lor (B_F \\land B_{70})  $\n","\n","**2. The three people are Brian, the person who studied History, the person who graduated on the 2nd.** <br>\n","\n","Note[6]: Based on Clue(2), Brian didn't study History since there is the other student who studied History.\n","\n","- $R_{6}$: $\\lnot B_H$\n","\n","Note[7]: If Brian didn't study History, then one of the other two students studied History.\n","\n","- $R_{7}$: $\\lnot B_H \\implies (A_H \\lor C_H)$\n","\n","Note[8 & 9]: Based on Clue(2), if a student studied History, then that student did not graduate on the 2nd.\n","\n","- $R_{8}$: $A_H \\implies \\lnot A_{2}$\n","\n","- $R_{9}$: $C_H \\implies \\lnot C_{2}$\n","\n","Note[10]: Based on Clue(2), Brian didn't graduated on the 2nd since there is the other student who graduated on the 2nd.\n","\n","- $R_{10}$: $\\lnot B_{2}$\n","\n","Note[11]: If Brian didn't graduate on the 2nd, then one of the other two students graduated on the 2nd.\n","\n","- $R_{11}$: $\\lnot B_{2} \\implies (A_{2} \\lor C_{2})$\n","\n","Note[12 & 13]: Based on Clue(2), if a student graduated on the 2nd, then that student did not study History.\n","\n","- $R_{12}$: $A_{2} \\implies \\lnot A_H$\n","\n","- $R_{13}$: $C_{2} \\implies \\lnot C_H$\n","\n","**3. Chen scored 70%, unless she studied history in which case her mark was 65%.** <br>\n","\n","Note[14]: Based on Clue(3), if Chen didn't studied History, then Chen scored 70%.\n","\n","- $R_{14}$: $\\lnot C_H \\implies C_{70}$\n","\n","Note[15]: Based on Clue(3), if Chen studied History, then Chen scored 65%.\n","\n","- $R_{15}$: $C_H \\implies C_{65}$\n","\n","**4. The mark of the person who graduated on the 3rd was 5% higher than Chen’s.** <br>\n","\n","Note[16]: Based on Clue(4), Chen didn't graduate on the 3rd since there is the other student who graduated on the 3rd.\n","\n","- $R_{16}$: $\\lnot C_{3}$\n","\n","Note[17]: If Chen didn't graduate on the 3rd, then one of the other two students graduated on the 3rd.\n","\n","- $R_{17}$: $\\lnot C_{3} \\implies (A_{3} \\lor B_{3})$\n","\n","Note[18]: Based on Clue(4), if Chen got 70% then Anlaji graduated on the 3rd and scored 75% (or) Brian graduated on the 3rd and scored 75%\n","\n","- $R_{18}$: $C_{70} \\implies (A_{3} \\land A_{75}) \\lor (B_{3} \\land B_{75})$\n","\n","Note[19]: Based on Clue(4), If Chen got 65% then Anlaji graduated on the 3rd and scored 70% (or) Brian graduated on the 3rd and scored 70%\n","\n","- $R_{19}$: $C_{65} \\implies (A_{3} \\land A_{70}) \\lor (B_{3} \\land B_{70})$\n","\n","\n","**5. Anjali did not graduate on the 2nd.** <br>\n","\n","Note[20]: Based on Clue(5), Anjali did not graduate on the 2nd.\n","\n","- $R_{20}$: $\\lnot A_{2}$\n","\n","Note[21]: If Anjali did not graduate on the 2nd, then one of the other two students graduated on the 2nd.\n","\n","- $R_{21}$: $\\lnot A_{2} \\implies (B_{2} \\lor C_{2})$\n","\n","**Constraints** <br>\n","\n","Note[22-39]: In order to avoid overlapping between students, subjects, scores & graduation dates, the following constraints will be applied.\n","\n","The following sentences use the formula:\n","$f(P,Q,R) = (P \\land\\lnot Q\\land\\lnot R)\\lor(\\lnot P \\land Q\\land\\lnot R)\\lor(\\lnot P \\land\\lnot Q\\land R)$\n","\n","- $R_{22}$: $f(A_F, A_G, A_H)$\n","- $R_{23}$: $f(B_F, B_G, B_H)$\n","- $R_{24}$: $f(C_F, C_G, C_H)$\n","<br>.\n","- $R_{25}$: $f(A_{65}, A_{70}, A_{75})$\n","- $R_{26}$: $f(B_{65}, B_{70}, B_{75})$\n","- $R_{27}$: $f(C_{65}, C_{70}, C_{75})$\n","<br>.\n","- $R_{28}$: $f(A_{2}, A_{3}, A_{4})$\n","- $R_{29}$: $f(B_{2}, B_{3}, B_{4})$\n","- $R_{30}$: $f(C_{2}, C_{3}, C_{4})$\n","<br>.\n","- $R_{31}$: $f(A_F, B_F, C_F)$\n","- $R_{32}$: $f(A_G, B_G, C_G)$\n","- $R_{33}$: $f(A_H, B_H, C_H)$\n","<br>.\n","- $R_{34}$: $f(A_{65}, B_{65}, C_{65})$\n","- $R_{35}$: $f(A_{70}, B_{70}, C_{70})$\n","- $R_{36}$: $f(A_{75}, B_{75}, C_{75})$\n","<br>.\n","- $R_{37}$: $f(A_{2}, B_{2}, C_{2})$\n","- $R_{38}$: $f(A_{3}, B_{3}, C_{3})$\n","- $R_{39}$: $f(A_{4}, B_{4}, C_{4})$\n","\n","**Model**\n","\n","|  0  |  1  |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 |\n","|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n","|$A_F$|$B_F$|$C_F$|$A_G$|$B_G$|$C_G$|$A_H$|$B_H$|$C_H$|$A_{65}$|$B_{65}$|$C_{65}$|$A_{70}$|$B_{70}$|$C_{70}$|$A_{75}$|$B_{75}$|$C_{75}$|$A_{2}$|$B_{2}$|$C_{2}$|$A_{3}$|$B_{3}$|$C_{3}$|$A_{4}$|$B_{4}$|$C_{4}$|"]},{"cell_type":"code","execution_count":null,"id":"61efe0d7","metadata":{"id":"61efe0d7"},"outputs":[],"source":["T = True\n","F = False\n","\n","model =  [\n","    T, T, T,\n","    F, F, F,\n","    T, T, T,\n","\n","    F, F, F,\n","    T, T, T,\n","    F, F, F,\n","\n","    T, T, T,\n","    F, F, F,\n","    T, T, T\n","]"]},{"cell_type":"code","execution_count":null,"id":"28ea6ef2","metadata":{"id":"28ea6ef2"},"outputs":[],"source":["implies = lambda P,Q: (not P) or Q\n","\n","Constraint = lambda P,Q,R: (P and not Q and not R) or (not P and Q and not R) or (not P and not Q and R)"]},{"cell_type":"code","execution_count":null,"id":"20948b84","metadata":{"id":"20948b84"},"outputs":[],"source":["KnowledgeBase = [\n","    # clue 1\n","    lambda model : not model[2], #R1\n","    lambda model : implies(not model[2], model[0] or model[1]), #R2\n","\n","    lambda model : not model[17], # R3\n","    lambda model : implies(model[14], (model[0] and model[15]) or (model[1] and model[16])), # R4\n","    lambda model : implies(model[11], (model[0] and model[15]) or (model[1] and model[16]) or # R5\n","                                                                    (model[0] and model[12]) or (model[1] and model[13])),\n","\n","    # clue 2\n","    lambda model : not model[7], # R6\n","    lambda model : implies(not model[7], model[6] or model[8]), # R7\n","    lambda model : implies(model[6], not model[18]), # R8\n","    lambda model : implies(model[8], not model[20]), # R9\n","\n","    lambda model : not model[19], #R10\n","    lambda model : implies(not model[19], model[18] or model[20]), # R11\n","    lambda model : implies(model[18], not model[6]), # R12\n","    lambda model : implies(model[20], not model[8]), # R13\n","\n","\n","    # clue 3\n","    lambda model : implies(not model[8], model[14]), # R14\n","    lambda model : implies(model[8], model[11]), # R15\n","\n","    # clue 4\n","    lambda model : not model[23], # R16\n","    lambda model : implies(not model[23], model[21] or model[22]), # R17\n","    lambda model : implies(model[11], (model[21] and model[12]) or (model[22] and model[13])), # R18\n","    lambda model : implies(model[14], (model[21] and model[15]) or (model[22] and model[16])), # R19\n","\n","    # clue 5\n","    lambda model : not model[18], # R20\n","    lambda model : implies(not model[18], model[19] or model[20]), # R21\n","\n","    # constraints\n","    lambda model : Constraint(model[0],model[3],model[6]), # R22\n","    lambda model : Constraint(model[1],model[4],model[7]), # R23\n","    lambda model : Constraint(model[2],model[5],model[8]), # R24\n","\n","    lambda model : Constraint(model[9],model[12],model[15]), # R25\n","    lambda model : Constraint(model[10],model[13],model[16]), # R26\n","    lambda model : Constraint(model[11],model[14],model[17]), # R27\n","\n","    lambda model : Constraint(model[18],model[21],model[24]), # R28\n","    lambda model : Constraint(model[19],model[22],model[25]), # R29\n","    lambda model : Constraint(model[20],model[23],model[26]), # R30\n","\n","    lambda model : Constraint(model[0],model[1],model[2]), # R31\n","    lambda model : Constraint(model[3],model[4],model[5]), # R32\n","    lambda model : Constraint(model[6],model[7],model[8]), # R33\n","\n","    lambda model : Constraint(model[9],model[10],model[11]), # R34\n","    lambda model : Constraint(model[12],model[13],model[14]), # R35\n","    lambda model : Constraint(model[15],model[16],model[17]), # R36\n","\n","    lambda model : Constraint(model[18],model[19],model[20]), # R37\n","    lambda model : Constraint(model[21],model[22],model[23]), # R38\n","    lambda model : Constraint(model[24],model[25],model[26]), # R39\n","]"]},{"cell_type":"code","execution_count":null,"id":"8a1866a3","metadata":{"id":"8a1866a3"},"outputs":[],"source":["import functools\n","\n","def evaluateKB(model, KnowledgeBase):\n","\n","    Result = [proposition(model) for proposition in KnowledgeBase]\n","    TrueOrFalse = functools.reduce(lambda a,b: a and b, Result)\n","\n","    return TrueOrFalse, Result"]},{"cell_type":"code","execution_count":null,"id":"6f1b914d","metadata":{"id":"6f1b914d"},"outputs":[],"source":["model =  [\n","    F, T, F,\n","    F, F, T,\n","    T, F, F,\n","\n","    T, F, F,\n","    F, F, T,\n","    F, T, F,\n","\n","    F, F, T,\n","    F, T, F,\n","    T, F, F\n","]"]},{"cell_type":"code","execution_count":null,"id":"3e8ef740","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1702524872067,"user":{"displayName":"Kaung Htet Hein","userId":"10372259901190129926"},"user_tz":0},"id":"3e8ef740","outputId":"249a58f7-eabe-49ee-f52c-5c8edd76ff9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["True: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"]}],"source":["TF, result = evaluateKB(model, KnowledgeBase)\n","\n","print(f\"{TF}: {result}\")"]},{"cell_type":"markdown","id":"1b43df95","metadata":{"id":"1b43df95"},"source":["## Task (b)\n","\n","\n","Use backtracking search to determine if your knowledge base is satisfiable and if so, identify a model that satisfies it."]},{"cell_type":"code","execution_count":null,"id":"68235ace","metadata":{"id":"68235ace"},"outputs":[],"source":["Clauses = [\n","    # clue 1\n","    ('~CF',), # R1\n","    ('CF', 'AF', 'BF'), # R2\n","\n","    ('~C75',), # R3\n","    ('BF', 'AF', '~C70'), ('B75', 'AF', '~C70'), ('BF', 'A75', '~C70'), ('B75', 'A75', '~C70'), # R4\n","    ('BF', 'AF', '~C65'), ('B75', 'AF', 'BF', '~C65'), ('BF', 'A75', 'AF', '~C65'), ('B75', 'A75', 'AF', 'BF', '~C65'), ('BF', 'AF', 'A70', '~C65'), # R5\n","    ('B75', 'AF', 'A70', 'BF', '~C65'), ('BF', 'A75', 'A70', '~C65'), ('B75', 'A75', 'A70', 'BF', '~C65'), ('BF', 'AF', 'B70', '~C65'), ('B75', 'AF', 'B70', '~C65'),\n","    ('BF', 'A75', 'AF', 'B70', '~C65'), ('B75', 'A75', 'AF', 'B70', '~C65'), ('BF', 'AF', 'A70', 'B70', '~C65'), ('B75', 'AF', 'A70', 'B70', '~C65'),\n","    ('BF', 'A75', 'A70', 'B70', '~C65'),('B75', 'A75', 'A70', 'B70', '~C65'),\n","\n","    # clue 2\n","    ('~BH',), # R6\n","    ('BH', 'AH', 'CH'), # R7\n","    ('~AH','~A2'), # R8\n","    ('~CH','~C2'), # R9\n","\n","    ('~B2',), # R10\n","    ('B2', 'A2', 'C2'), # R11\n","    ('~A2','~AH'), # R12\n","    ('~C2','~CH'), # R13\n","\n","    # clue 3\n","    ('CH', 'C70'), # R14\n","    ('~CH', 'C65'), # R15\n","\n","    # clue 4\n","    ('~C3',), # R16\n","    ('C3', 'A3', 'B3'), # R17\n","    ('B3', 'A3', '~C70'), ('B75', 'A3', '~C70'), ('B3', 'A75', '~C70'), ('B75', 'A75', '~C70'), # R18\n","    ('B3', 'A3', '~C65'), ('B70', 'A3', '~C65'), ('B3', 'A70', '~C65'), ('B70', 'A70', '~C65'), # R19\n","\n","    # clue 5\n","    ('~A2',), # R20\n","    ('A2', 'B2', 'C2'), # R21\n","\n","    # constraints\n","    ('AF', 'AG', 'AH'), ('~AF', '~AG'), ('~AF', '~AH'), ('~AG', '~AH'), # R22\n","    ('BF', 'BG', 'BH'), ('~BF', '~BG'), ('~BF', '~BH'), ('~BG', '~BH'), # R23\n","    ('CF', 'CG', 'CH'), ('~CF', '~CG'), ('~CF', '~CH'), ('~CG', '~CH'), # R24\n","\n","    ('A65', 'A70', 'A75'), ('~A65', '~A70'), ('~A65', '~A75'), ('~A70', '~A75'), # R25\n","    ('B65', 'B70', 'B75'), ('~B65', '~B70'), ('~B65', '~B75'), ('~B70', '~B75'), # R26\n","    ('C65', 'C70', 'C75'), ('~C65', '~C70'), ('~C65', '~C75'), ('~C70', '~C75'), # R27\n","\n","    ('A2', 'A3', 'A4'), ('~A2', '~A3'), ('~A2', '~A4'), ('~A3', '~A4'), # R28\n","    ('B2', 'B3', 'B4'), ('~B2', '~B3'), ('~B2', '~B4'), ('~B3', '~B4'), # R29\n","    ('C2', 'C3', 'C4'), ('~C2', '~C3'), ('~C2', '~C4'), ('~C3', '~C4'), # R30\n","\n","    ('AF', 'BF', 'CF'), ('~AF', '~BF'), ('~AF', '~CF'), ('~BF', '~CF'), # R31\n","    ('AG', 'BG', 'CG'), ('~AG', '~BG'), ('~AG', '~CG'), ('~BG', '~CG'), # R32\n","    ('AH', 'BH', 'CH'), ('~AH', '~BH'), ('~AH', '~CH'), ('~BH', '~CH'), # R33\n","\n","    ('A65', 'B65', 'C65'), ('~A65', '~B65'), ('~A65', '~C65'), ('~B65', '~C65'), # R34\n","    ('A70', 'B70', 'C70'), ('~A70', '~B70'), ('~A70', '~C70'), ('~B70', '~C70'), # R35\n","    ('A75', 'B75', 'C75'), ('~A75', '~B75'), ('~A75', '~C75'), ('~B75', '~C75'), # R36\n","\n","    ('A2', 'B2', 'C2'), ('~A2', '~B2'), ('~A2', '~C2'), ('~B2', '~C2'), # R37\n","    ('A3', 'B3', 'C3'), ('~A3', '~B3'), ('~A3', '~C3'), ('~B3', '~C3'), # R38\n","    ('A4', 'B4', 'C4'), ('~A4', '~B4'), ('~A4', '~C4'), ('~B4', '~C4'), # R39\n","]"]},{"cell_type":"code","execution_count":null,"id":"49391856","metadata":{"id":"49391856"},"outputs":[],"source":["Symbols = (\n","    'AF','BF','CF',\n","    'AG','BG','CG',\n","    'AH','BH','CH',\n","\n","    'A65','B65','C65',\n","    'A70','B70','C70',\n","    'A75','B75','C75',\n","\n","    'A2','B2','C2',\n","    'A3','B3','C3',\n","    'A4','B4','C4',\n",")\n","\n","Model =  {i:None for i in Symbols}"]},{"cell_type":"code","execution_count":null,"id":"3356c57b","metadata":{"id":"3356c57b"},"outputs":[],"source":["def EvaluateKB(Clauses, Model):\n","    EvaluatedClauses = []\n","\n","    for clause in Clauses:\n","        EvaluatedLiterals = []\n","\n","        for literal in clause:\n","            if literal[0] == '~':\n","                if Model[literal[1:]] is None:\n","                    EvaluatedLiterals.append(None)\n","                else:\n","                    EvaluatedLiterals.append(not Model[literal[1:]])\n","            else:\n","                if Model[literal] is None:\n","                    EvaluatedLiterals.append(None)\n","                else:\n","                    EvaluatedLiterals.append(Model[literal])\n","\n","        if True in EvaluatedLiterals:\n","            EvaluatedClauses.append(True)\n","        elif None in EvaluatedLiterals:\n","            EvaluatedClauses.append(None)\n","        else:\n","            EvaluatedClauses.append(False)\n","\n","    if all(i is True for i in EvaluatedClauses):\n","        EvaluatedKB = True\n","    elif False in EvaluatedClauses:\n","        EvaluatedKB = False\n","    else:\n","        EvaluatedKB = None\n","\n","    return EvaluatedKB"]},{"cell_type":"code","execution_count":null,"id":"a6953a0c","metadata":{"id":"a6953a0c"},"outputs":[],"source":["import copy\n","\n","def BackTrackingSearch(Clauses, Model, model_count=0):\n","\n","    EvaluatedClauses = EvaluateKB(Clauses, Model)\n","\n","    if EvaluatedClauses is True:\n","        return True, Model, model_count\n","    elif EvaluatedClauses is False:\n","        return False, None, model_count\n","    else:\n","        model_count += 1 # for 1(e) evaluation\n","\n","        Model2 = copy.deepcopy(Model)\n","        NextSymbol = [i for i in Model2 if Model2[i] is None][0]\n","\n","        Model2[NextSymbol] = True\n","        ModelTrue, SATModel, model_count = BackTrackingSearch(Clauses, Model2, model_count)\n","        if ModelTrue:\n","            return True, SATModel, model_count\n","\n","        Model2[NextSymbol] = False\n","        ModelFalse, SATModel, model_count = BackTrackingSearch(Clauses, Model2, model_count)\n","        if ModelFalse:\n","            return True, SATModel, model_count\n","\n","    return False, None, model_count"]},{"cell_type":"code","execution_count":null,"id":"9465b100","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1702524885855,"user":{"displayName":"Kaung Htet Hein","userId":"10372259901190129926"},"user_tz":0},"id":"9465b100","outputId":"a116ddbc-a741-48e3-f499-e732f38928bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["True {'AF': False, 'BF': True, 'CF': False, 'AG': False, 'BG': False, 'CG': True, 'AH': True, 'BH': False, 'CH': False, 'A65': True, 'B65': False, 'C65': False, 'A70': False, 'B70': False, 'C70': True, 'A75': False, 'B75': True, 'C75': False, 'A2': False, 'B2': False, 'C2': True, 'A3': False, 'B3': True, 'C3': False, 'A4': True, 'B4': False, 'C4': False}\n","Model Count: 91\n"]}],"source":["result, SATModel, model_count = BackTrackingSearch(Clauses, Model)\n","\n","print(result, SATModel)\n","print(f\"Model Count: {model_count}\")"]},{"cell_type":"markdown","id":"76668aa0","metadata":{"id":"76668aa0"},"source":["## Task (c)\n","\n","Determine whether your KB is uniquely satisfiable."]},{"cell_type":"code","execution_count":null,"id":"abb1af01","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1137015,"status":"ok","timestamp":1702526044145,"user":{"displayName":"Kaung Htet Hein","userId":"10372259901190129926"},"user_tz":0},"id":"abb1af01","outputId":"ac095a1c-9117-448f-eaa5-d9135c45528b"},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n"," True Model Count 1: True, (False, True, False, False, False, True, True, False, False, True, False, False, False, False, True, False, True, False, False, False, True, False, True, False, True, False, False)\n","[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n","Iteration Count: 97381292\n"]}],"source":["import itertools\n","\n","Models = itertools.product((T,F), repeat=27)\n","\n","TrueModelCount = 0\n","IterationCount = 0 # for 1(e) evaluation\n","\n","for m in Models:\n","    IterationCount += 1\n","    TF, Result =  evaluateKB(m, KnowledgeBase)\n","    if TF:\n","        TrueModelCount += 1\n","        print(f\"---\\n True Model Count {TrueModelCount}: {TF}, {m}\")\n","        print(Result)\n","        print(f\"Iteration Count: {IterationCount}\")\n","\n","if TrueModelCount == 0:\n","    print(\"No true models found after iterating through all possible models.\")"]},{"cell_type":"markdown","id":"3165899c","metadata":{"id":"3165899c"},"source":["## Task (d)\n","\n","- Improve the backtracking search method by eliminating “trivial solutions”entailed by so-called unit clauses in the Conjunctive Normal Form of the KB that involve only one literal.\n","- Clauses such as (P,) or ('~P',) determine the state the literal must take for the KB to be satisfied.\n","- Write a function to identify such clauses and generate a Model in which the states of literals that can be determined from unit clauses are prepopulated.\n","- You do not need to modify the BackTrackingSearch function."]},{"cell_type":"code","execution_count":null,"id":"97564199","metadata":{"id":"97564199"},"outputs":[],"source":["def IdentifyUnitClauses(Clauses):\n","    UnitClauses = []\n","\n","    for clause in Clauses:\n","        if len(clause) == 1:\n","            UnitClauses.append(clause)\n","\n","    return UnitClauses"]},{"cell_type":"code","execution_count":null,"id":"f3e28f66","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1702524894491,"user":{"displayName":"Kaung Htet Hein","userId":"10372259901190129926"},"user_tz":0},"id":"f3e28f66","outputId":"f03f6e84-dc51-4fd0-d8a0-1126db3170e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('~CF',), ('~C75',), ('~BH',), ('~B2',), ('~C3',), ('~A2',)]\n"]}],"source":["UnitClauses = IdentifyUnitClauses(Clauses)\n","\n","print(UnitClauses)"]},{"cell_type":"code","execution_count":null,"id":"4caec925","metadata":{"id":"4caec925"},"outputs":[],"source":["def PrepopulateUnitClauses(Clauses, Model):\n","    UnitClauses = IdentifyUnitClauses(Clauses)\n","\n","    for clause in UnitClauses:\n","        literal = clause[0]\n","        if literal[0] == '~':\n","            Model[literal[1:]] = False\n","        else:\n","            Model[literal] = True\n","\n","    return Model"]},{"cell_type":"code","execution_count":null,"id":"3c2a70b8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702524898736,"user":{"displayName":"Kaung Htet Hein","userId":"10372259901190129926"},"user_tz":0},"id":"3c2a70b8","outputId":"3315d6dd-38a8-4609-809c-42a6df99aa95"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'AF': None, 'BF': None, 'CF': False, 'AG': None, 'BG': None, 'CG': None, 'AH': None, 'BH': False, 'CH': None, 'A65': None, 'B65': None, 'C65': None, 'A70': None, 'B70': None, 'C70': None, 'A75': None, 'B75': None, 'C75': False, 'A2': False, 'B2': False, 'C2': None, 'A3': None, 'B3': None, 'C3': False, 'A4': None, 'B4': None, 'C4': None}\n"]}],"source":["PrepopulatedModel = PrepopulateUnitClauses(Clauses, Model)\n","\n","print(PrepopulatedModel)"]},{"cell_type":"code","execution_count":null,"id":"d361e5ac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1702524900502,"user":{"displayName":"Kaung Htet Hein","userId":"10372259901190129926"},"user_tz":0},"id":"d361e5ac","outputId":"19715fab-6fd2-4643-f337-e4470c3b137a"},"outputs":[{"name":"stdout","output_type":"stream","text":["True {'AF': False, 'BF': True, 'CF': False, 'AG': False, 'BG': False, 'CG': True, 'AH': True, 'BH': False, 'CH': False, 'A65': True, 'B65': False, 'C65': False, 'A70': False, 'B70': False, 'C70': True, 'A75': False, 'B75': True, 'C75': False, 'A2': False, 'B2': False, 'C2': True, 'A3': False, 'B3': True, 'C3': False, 'A4': True, 'B4': False, 'C4': False}\n","Model Count: 67\n"]}],"source":["BackTrackingSearch(Clauses, PrepopulatedModel)\n","result, SATModel, model_count = BackTrackingSearch(Clauses, PrepopulatedModel)\n","\n","print(result, SATModel)\n","print(f\"Model Count: {model_count}\")"]},{"cell_type":"markdown","id":"36718e5b","metadata":{"id":"36718e5b"},"source":["## Task (e)\n","\n","- For each of the methods of solution used in parts b, c, and d, calculate how many models were evaluated before a solution was found (you will need to\n","modify the code to do this).\n","- Does this correspond to your expectations?\n","- What factors might influence the relative performance of these methods on a specific problem?"]},{"cell_type":"markdown","id":"0d0614ab","metadata":{"id":"0d0614ab"},"source":["**Solution: Students' Subject, Marks & their Graduation Date**\n","\n","| Student | Subject | Mark | Graduated Date |\n","| ----------- | ----------- | ----------- | ----------- |\n","| Anjali | History | Very Good 65% | 4th July |\n","| Brian | French | Outstanding 75% | 3rd July |\n","| Chen | Geography | Excellent 70% | 2nd July |\n","\n","**Unique SAT Model**\n","\n","model =  [F, T, F, F, F, T, T, F, F, T, F, F, F, F, T, F, T, F, F, F, T, F, T, F, T, F, F]"]},{"cell_type":"markdown","id":"7f470150","metadata":{"id":"7f470150"},"source":["For this project, three approaches were applied to find the solution.\n","<br>\n","\n","The first approach 1(b) is a backtracking search which is a SAT solver. It looks for a model that satisfies the Knowledge Base (KB). To apply backtracking search to the KB, sentences were first transformed into the Conjuctive Normal Form (CNF).\n","<br>\n","\n","The second approach 1(c) is a model checking, which uses a crude way of enumerating and iterating through the truth table to find all the possible models that satisfy the KB.\n","<br>\n","\n","The third approach 1(d) is a improved version of backtracking search. It trims the search space by identifying the unit clauses and prepopulating the model with their states.\n","<br>\n","\n","Among the three approaches, 1(d) is the most efficient approach which found the soulation with 67 iterations, followed by 1(b) with 91 iterations. On the other hand, 1(c) has to iterate 97,381,292 times to get the unique SAT model. 1(d) & 1(b) performed their tasks instantly while 1(c) took approximately 36 minutes and 22 seconds to iterate all 134,217,728 possible models in the truth table.\n","<br>\n","\n","1(d) and 1(b) are reliable approaches compared to 1(c). However, these models stopped after they found their first SAT model which made it difficult to determine the uniqueness of the SAT model.  Another problem is transparency. Due to this, it is difficult to improve the KB with just backtracking search.\n","<br>\n","\n","On the other hand, 1(c), model checking is reliable in tracking errors or improvment. But the downside of it is consumption of time and computational power. These increase in relation to the number of atomic propositions. The proposed model has 27 atomic propositions which leads to over 130 million possible models.\n","<br>\n","\n","Other problems faced during the development of this KB are balancing the complexity & interpretability of the sentences. Assigning the right amount of atomic propositions was also challenging. One last problem is transforming a sentence into CNF. As an example, R5 is very complex to transform into CNF manually.\n","<br>\n","\n","In conclusion, back tracking search with trimming is the most reliable approach. However, to imporve the model performance, model checking was required."]},{"cell_type":"code","execution_count":null,"id":"d7a0aef0","metadata":{"id":"d7a0aef0"},"outputs":[],"source":["\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}